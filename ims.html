<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IMS</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700&family=Poppins:wght@400;700&family=Manrope:wght@400;500;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="./css/ims.css">
    
</head>
<body>
  <div class="topnav">
    <div class="hamburger" onclick="toggleMenu()">â˜°</div>
    <a href="index.html">Home</a>
    <a href="index.html#works">Works</a>
    <a href="https://github.com/jihyeon26">Github</a>
    <a href="about.html">About</a>
    <a href="artworks.html">Artworks</a>
  </div>
  <header>
      <div class="container">
          <p class="project-tag">IMS</p>
          <h1>Weaving Your Travel Moments into Timeless Stories</h1>
      </div>
  </header>

  <div class="image-link">
    <div class="image-container">
      <div class="gradient-circle" style="background-color: rgb(231, 191, 139);"></div>
      <img class="cover" src="./assets/ims/ims_door.png" style="width: 80%; height: auto;display: block; margin:0 auto;" alt="IMS Project">                  
    </div>
  </div>

  <section class="overview">
      <div class="container">
        <h2>Overview</h2>
        <p>
          IMS (Image to Story) is an AI-powered platform designed to turn your travel photos into compelling narratives. By analyzing metadata like location, time, and additional user-provided inputs, IMS generates personalized and emotional travel stories, providing a unique way to preserve and share your memories.
        </p>
        
        <img src="./assets/ims/story.png" style="width: 70%; border: 1px solid #d4d4d4; border-radius: 15px; margin:0 auto; margin-top: 40px;display: block;">
    </div>
  </section>

  <section class="role">
      <div class="container">
          <h2>My role</h2>
          <p>I led the development of the core OpenAI integration, designed the overall program structure, and created prototypes to refine and concretize the service. I also defined user input parameters and conducted extensive testing and optimization to improve the system's generation performance.</p>
          <ul>
            <li><strong>Me: </strong>Machine Learning Lead, UI/UX Designer</li>
            <li><strong>Geonjin Jung:</strong> Team Leader</li>
            <li><strong>Daegeon Lim:</strong> Project Manager</li>
            <li><strong>Jaei Lee:</strong> Project Management Office</li>
            <li><strong>Hoyoung Kim:</strong> Frontend Lead.</li>
            <li><strong>Euijin Ahn:</strong> Technical/Backend Lead.</li>
            <li><strong>Hyunyoung Lee:</strong> Data Engineer.</li>
            <li><strong>Sumin Kim:</strong> Machine Learning Engineer.</li>
            <li><strong>Hyundong Lee:</strong> Service Planner/QA.</li>
          </ul>
      </div>
  </section>

  <section class="details">
      <div class="container-target">
          <div class="detail-item">
              <h3>Target users</h3>                              
                  <p>Travelers looking for an effortless way to document and share their journeys.</p>              
          </div>
          <div class="detail-item">
              <h3>Interface</h3>
              <p>Website</p>
          </div>
          <div class="detail-item">
              <h3>Timeline</h3>
              <p>2 weeks</p>
          </div>
      </div>
  </section>

  <section class="business-opportunity">
    <div class="container">
      <h2>Key Features</h2>
      <ul>
        <li><strong>Automatic Story Generation:</strong> Upload photos, and our AI crafts a travel narrative.</li>
        <li><strong>Emotionally Rich Narratives:</strong> Stories capture the essence of your experiences.</li>
        <li><strong>Easy Sharing:</strong> Save your stories in blog format and share them with friends and family.</li>
      </ul>
    </div>
  </section>

  <section class="problems-section">
      <div class="container2">
        <h2>Problems Solving</h2> 

        <div class="problem">
          <h3>Problem 1</h3>
          <p>When users upload only images, the system sometimes generates stories with incorrect or irrelevant locations, creating a disconnect between the userâ€™s actual experience and the narrative.</p>
          <p><span class="solution">ðŸ’¡ Solution:</span> To ensure accuracy, we extract EXIF metadata from photos to retrieve precise location data. Additionally, we utilize image recognition to identify landmarks, allowing the system to construct a story grounded in the user's real journey.</p>
        </div>

        <div class="problem">
          <h3>Problem 2</h3>
          <p>Without additional context, the system occasionally describes individuals in photos using generic terms, such as "a woman," leading to impersonal and awkward storytelling.</p>
          <p><span class="solution">ðŸ’¡ Solution:</span> By enabling users to input details such as gender and information about their companions, we enrich the narrative with meaningful context, transforming descriptions into more personalized and relatable stories.</p>
        </div>

        <div class="problem">
          <h3>Problem 3</h3>
          <p>Many users find it burdensome to sort through their travel photos and write detailed accounts of their experiences, leading to missed opportunities to preserve their memories.</p>
          <p><span class="solution">ðŸ’¡ Solution:</span> Our platform minimizes user effort by automating the story creation process. With minimal input, the system crafts a cohesive and emotional travel narrative, allowing users to focus on reliving their memories rather than organizing them.</p>
        </div>          
      </div>
  </section>

  <section class="data-process">
    <div class="container">
        
        <h2>Prototype</h2>
        <img src="./assets/ims/prototype.png" style="width: 100%; margin: 40px 0px;">
        <img src="./assets/ims/prototype_code.png" style="width: 80%; display: block; margin: auto;">
        <p>The initial prototype used the PIL and Geopy libraries to convert GPS data into readable addresses. For better performance, the system was later enhanced in the areas of location data, computer vision, and OpenAI. Details are provided below.</p>

        <br><br>


        <h2>Improvements</h2>
        <img src="./assets/ims/model.png" style="width: 100%; margin: 40px 0px;">

        <h3>1. Extract location (Azure Map API, Azure Computer Vision, Google Cloud Vision)</h3>
        <p>Step 1 - Azure Maps: Extract GPS metadata from the image's EXIF data to identify landmarks, cities, and countries.
        </p>
        <p>Step 2 - Azure Computer Vision: Perform landmark detection. If successful, the process ends here. While highly accurate for detected landmarks, the scope of recognizable landmarks is limited. If detection fails, proceed to Step 3.
        </p>
        <p>Step 3 - Google Cloud Vision: Attempt landmark detection. This tool recognizes a wide range of landmarks but sometimes provides overly detailed or inaccurate results.
        </p>
        <img src="./assets/ims/maps.png" style="width: 100%; margin-bottom:60px">


        <h3>2. Generate Caption (Azure Computer Vision)</h3>
        <p>Images are uploaded and analyzed using the Azure Computer Vision API via Azure Portal. The API generates dense captions along with confidence scores for each caption.
        Images are resized to a maximum of 1290x1080 for efficient processing, and dense captions with confidence scores above 0.5 are filtered. The processing time is calculated, and data is organized.
        </p>
        <p>Initially, only captions with confidence scores above 0.5 were displayed. However, if all confidence scores fell below 0.5, no captions were outputted. This issue was resolved by displaying only the caption with the highest confidence score.
        During visualization, it was observed that the caption with the highest confidence score did not always accurately describe the image. To address this, multiple captions are now displayed to provide a comprehensive result.
        </p>
        <img src="./assets/ims/caption.png" style="width: 100%; margin-bottom:60px">

        <h3>3. Generate Story (Azure OpenAI)</h3>
        <p>
            Captions and location data are processed by Azure OpenAI, which synthesizes the content into coherent travel stories. The integration ensures personalized and contextually relevant narratives.
        </p>
        <div class="image-container2">     
            <img src="./assets/ims/feature1.png" alt="Image 1">
            
            <img src="./assets/ims/feature2.png" alt="Image 2">
        </div>

    </div>
</section>

<section class="tools">
  <div class="container">
      <h2>Tools Used</h2>
      <h3>UI/UX Frontend</h3>
      <ul>
          <li>Figma</li>
          <li>TypeScript & JavaScript</li>
          <li>React</li>
      </ul>

      <h3>Backend</h3>
      <ul>
          <li>GORM & Fiber (Go)</li>
          <li>Azure Database</li>
      </ul>

      <h3>Machine Learning and AI</h3>
      <ul>
          <li>Azure Maps API</li>
          <li>Azure Computer Vision</li>
          <li>Azure OpenAI API</li>
      </ul>

      <h3>Infrastructure</h3>
      <ul>
          <li>Azure Blob Storage</li>
          <li>Azure VM</li>
          <li>Azure Database</li>
      </ul>
  </div>
</section>


</section>
<section>
  <div class="container">
      <h2>UI Design</h2><br>
      <p>
          
      </p>
      <div class="image-container3">     
          <img src="./assets/ims/ui_d.png" alt="ui 1" class="responsive-image">
          <img src="./assets/ims/ui2.png" alt="ui 2" class="responsive-image">
      </div>     
  </div>
</section>

<div id="footer" class="section">
    <div class="container">
      <p>          
        Copyright 2024. Jihyeon Choung All rights reserved.
      </p>
    </div>
</div>
        
<script src="./javascript/machuilin.js"></script>
</body>

</html>